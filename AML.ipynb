{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4413279-6a13-4a88-8fdd-dd4fdd2e9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\envs\\cv\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ptls.nn.trx_encoder.glove_embedding import GloveEmbedding\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from ptls.nn import RnnSeqEncoder, TrxEncoder\n",
    "from ptls.nn.trx_encoder.trx_encoder_tlf import TrxEncoderTLF\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "import ptls\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pickle as pkl\n",
    "from ptls.frames.coles.losses import ContrastiveLoss\n",
    "\n",
    "import logging\n",
    "\n",
    "import ptls\n",
    "from ptls.preprocessing.deeptlf.src import DeepTLF, TreeDrivenEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a544e-4cd9-4e51-b1cf-810180390c26",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d01b4a-89df-45e5-83e8-502167864b47",
   "metadata": {},
   "source": [
    "#### #1 Age bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3e180d-681a-4c8f-a70a-e7a407a933a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/age_bins'\n",
    "\n",
    "df_params = {\n",
    "    \"features\" : [\"amount_rur\", \"small_group\"],\n",
    "    \"cat_cols\" : [\"small_group\"],\n",
    "    \"numeric_cols\" : [\"amount_rur\"],\n",
    "    \"cat_unique\" : [],\n",
    "    \"date_col\" : \"trans_date\",\n",
    "    \"id_col\" : \"client_id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2abf78-e143-4812-b474-2dc946cf4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = pd.read_csv(os.path.join(data_path, 'transactions_train.csv'))\n",
    "\n",
    "for f in df_params[\"cat_cols\"] + [df_params[\"date_col\"]]:\n",
    "    df_params[\"cat_unique\"].append(source_data[f].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9ca82-9f77-45c6-9b2d-7459bf3d88b9",
   "metadata": {},
   "source": [
    "#### #2 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22636181-dd00-4c10-b9a4-cb0dbf361988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/gender'\n",
    "\n",
    "source_data = pd.read_csv(os.path.join(data_path, 'transactions.csv'))\n",
    "source_data = source_data.drop(columns=[\"term_id\"]) \n",
    "\n",
    "source_data.tr_datetime = [int(i.split()[0]) for i in source_data.tr_datetime.values]\n",
    "\n",
    "df_params = {\n",
    "    \"features\" : [\"mcc_code\", \"tr_type\", \"amount\"],\n",
    "    \"numeric_cols\" : [\"amount\"],\n",
    "    \"cat_cols\" : [\"mcc_code\", \"tr_type\"],\n",
    "    \"cat_unique\" : [],\n",
    "    \"date_col\" : \"tr_datetime\",\n",
    "    \"id_col\" : \"customer_id\"\n",
    "}\n",
    "\n",
    "for f in df_params[\"cat_cols\"] + [df_params[\"date_col\"]]:\n",
    "    df_params[\"cat_unique\"].append(source_data[f].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b520bb-ad24-4dd8-b1d5-9b96bfae552f",
   "metadata": {},
   "source": [
    "#### #3 rosbank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3306116-1bc4-4562-ad06-6e1efc2ba8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df3dddc-a287-488d-baab-821043fefd4c",
   "metadata": {},
   "source": [
    "## DeepTLF Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290dfa8-9429-4521-a316-f71cd482d401",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c39120-655b-4945-aa41-db4605caeeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"n_est\" : 20,\n",
    "          \"max_depth\" : 6,\n",
    "          \"xgb_lr\" : 0.01,\n",
    "          \"min_freq\" : 5\n",
    "         }\n",
    "\n",
    "tree_encoder = DeepTLF(**params)\n",
    "split_conditions = tree_encoder.fit(source_data[df_params[\"features\"]])\n",
    "len(split_conditions)\n",
    "#encoded_data = tree_encoder.transform(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac8a08c-87f0-47e2-93dd-de8fdce2cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moved to tlf encoder\n",
    "\n",
    "# df_params[\"features\"] = [f\"ef_{i}\" for i in range(encoded_data.shape[1])]\n",
    "# encoded_data = pd.DataFrame(encoded_data, columns=df_params[\"features\"])\n",
    "# encoded_data[df_params['id_col']] = source_data[df_params['id_col']]\n",
    "# encoded_data[df_params['date_col']] = source_data[df_params['date_col']]\n",
    "# del source_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf857fd-9b76-4c2f-9495-b6f49faf80d1",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00c2305-c44e-4b82-bead-69f2f252b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id=df_params['id_col'],\n",
    "    col_event_time=df_params['date_col'],\n",
    "    event_time_transformation='none',\n",
    "    cols_numerical=df_params[\"features\"],\n",
    "    return_records=True,\n",
    ")\n",
    "\n",
    "dataset = preprocessor.fit_transform(source_data)\n",
    "dataset = sorted(dataset, key=lambda x: x[df_params['id_col']])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "len(train), len(test)\n",
    "\n",
    "del dataset, source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31187c43-2b35-40bd-aacc-450555a05391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/age_bins/train_encoded.pkl\", \"wb\") as f:\n",
    "    pkl.dump(train, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "with open(\"data/age_bins/test_encoded.pkl\", \"wb\") as f:\n",
    "    pkl.dump(test, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4393f6d2-f012-44a5-9082-515b04013392",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/age_bins/train_encoded.pkl\", \"rb\") as f:\n",
    "    train = pkl.load(f)\n",
    "with open(\"data/age_bins/test_encoded.pkl\", \"rb\") as f:\n",
    "    test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb99366-bbbd-4fc3-9def-8d68d3fed5d7",
   "metadata": {},
   "source": [
    "## CoLES training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9fa1fe-2dc7-43fa-85b0-739941b8ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_rur\n"
     ]
    }
   ],
   "source": [
    "#Basic trx encoder\n",
    "\n",
    "embeddings=dict()\n",
    "for i, f in enumerate(df_params[\"cat_cols\"] + [df_params[\"date_col\"]]):\n",
    "    embeddings[f] = {'in' : df_params[\"cat_unique\"][i], 'out' : 16}\n",
    "\n",
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values=dict([(fe, 'identity') for fe in df_params['numeric_cols']]),\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12223540-1050-4208-8f1d-9cb4861343f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TLF trx encoder\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoderTLF(encoder=tree_encoder, feature_names=df_params[\"features\"]),\n",
    "    hidden_size=256,\n",
    "    type='gru',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe2f113-db1f-4b44-ac22-28ab154fb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867cc6f3-416f-4d3b-9404-b9a511636be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        MemoryMapDataset(\n",
    "            data=train,\n",
    "            i_filters=[\n",
    "                SeqLenFilter(min_seq_len=25),\n",
    "            ],\n",
    "        ),\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=200,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=1,\n",
    "    train_batch_size=128,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=12,\n",
    "    accelerator=\"cuda\",\n",
    "    #devices=1,\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2819b50-3265-49db-8725-636f9b547e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\envs\\cv\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 1.5 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.924     Total estimated model params size (MB)\n",
      "C:\\Users\\peter\\anaconda3\\envs\\cv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818f493f8b81482eac5f9a3e1ef88e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=12` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(68.1145), 'seq_len': tensor(100.2608)}\n"
     ]
    }
   ],
   "source": [
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model, train_dl)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a63836c2-e379-477e-8393-4e1c81854eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq_encoder.state_dict(), \"models/coles-tlf1650-gen.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fd889f-3f52-409a-be52-806165d588da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder.load_state_dict(torch.load(\"models/coles-tlf1800-age.pt\"))\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f3505-aa20-4a97-acff-d5a951f0bf2c",
   "metadata": {},
   "source": [
    "## Testing embeddings via different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93de007-c063-4cc7-a1a2-85b4d2dea2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\peter\\anaconda3\\envs\\cv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c9c33412e488eb1368118594be9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\envs\\cv\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py:173: UserWarning: Lightning couldn't infer the indices fetched for your dataloader.\n",
      "  warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3b3ec77526447d9972367e47656509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000, 256]), torch.Size([6000, 256]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ptls.data_load.datasets import inference_data_loader\n",
    "\n",
    "train_dl = inference_data_loader(train, num_workers=0, batch_size=256)\n",
    "train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "\n",
    "test_dl = inference_data_loader(test, num_workers=0, batch_size=256)\n",
    "test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
    "\n",
    "train_embeds.shape, test_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84326e63-dcc2-4d07-aa3b-b7fc151f65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_age_bins_scenario(df_params, train_embeds, test_embeds):\n",
    "    data_path = \"data/age_bins\"\n",
    "    \n",
    "    df_target = pd.read_csv(os.path.join(data_path, 'train_target.csv'))\n",
    "    df_target = df_target.set_index(df_params[\"id_col\"])\n",
    "    df_target.rename(columns={\"bins\": \"target\"}, inplace=True)\n",
    "    \n",
    "    train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
    "    train_df[df_params[\"id_col\"]] = [x[df_params[\"id_col\"]] for x in train]\n",
    "    train_df = train_df.merge(df_target, how='left', on=df_params[\"id_col\"])\n",
    "    \n",
    "    test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
    "    test_df[df_params[\"id_col\"]] = [x[df_params[\"id_col\"]] for x in test]\n",
    "    test_df = test_df.merge(df_target, how='left', on=df_params[\"id_col\"])\n",
    "    return train_df, test_df\n",
    "\n",
    "def get_train_test_gender_scenario(df_params, train_embeds, test_embeds):\n",
    "    data_path = \"data/gender\"\n",
    "    \n",
    "    df_target = pd.read_csv(os.path.join(data_path, 'gender_train.csv'))\n",
    "    df_target = df_target.set_index(df_params[\"id_col\"])\n",
    "    df_target.rename(columns={\"gender\": \"target\"}, inplace=True)\n",
    "    \n",
    "    train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
    "    train_df[df_params[\"id_col\"]] = [x[df_params[\"id_col\"]] for x in train]\n",
    "    train_df = train_df.merge(df_target, how='left', on=df_params[\"id_col\"])\n",
    "    \n",
    "    test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
    "    test_df[df_params[\"id_col\"]] = [x[df_params[\"id_col\"]] for x in test]\n",
    "    test_df = test_df.merge(df_target, how='left', on=df_params[\"id_col\"])\n",
    "    train_df = train_df.fillna(2)\n",
    "    test_df = test_df.fillna(2)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61918160-a3e6-4826-b5f8-22132783d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00294a1c-0bd0-4892-a72c-144cd4829eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_df, test_df = get_train_test_age_bins_scenario(df_params, train_embeds, test_embeds)\n",
    "\n",
    "#train_df, test_df = get_train_test_gender_scenario(df_params, train_embeds, test_embeds)\n",
    "\n",
    "embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
    "x_train, y_train = train_df[embed_columns], train_df['target']\n",
    "x_test, y_test = test_df[embed_columns], test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee3f44b-5546-431b-8edd-331d241b73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.coles.sampling_strategies import HardNegativePairSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e5507-8f24-431c-a191-cf922f1608ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ContrastiveLoss(margin=0.5, sampling_strategy=HardNegativePairSelector(neg_count=5))\n",
    "cl(torch.tensor(x_test.values), torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c3c08da-31b8-489d-9863-4f8ee0109e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13260.634666666667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "79563808/6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b60fef-87ae-4576-b11b-f3e2d2c23b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79563808 main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c31ea1-9539-4c81-b4e8-09e30529c763",
   "metadata": {},
   "source": [
    "#### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8192c53e-0f40-4631-af8a-a7e2f491df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 0\n",
    "num_iters = 3\n",
    "\n",
    "for i in range(num_iters):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    sc += clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485aeed8-e367-4173-aeaa-21c2bcd85c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4481111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc/num_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8916f5d-b07e-47c3-be3c-fdceabf1f190",
   "metadata": {},
   "source": [
    "#### GB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37753d78-1979-4faf-b597-2de8a0819a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 64973\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -1.161020\n",
      "[LightGBM] [Info] Start training from score -1.394999\n",
      "[LightGBM] [Info] Start training from score -0.823256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43633333333333335"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c80d8c-11b7-40a5-9e11-b8495c79ac03",
   "metadata": {},
   "source": [
    "#### KNeighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd218067-0895-4a5f-8b48-647503a01f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.396"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "neigh.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531bbe5-a7cb-4a42-9281-ce55b98848f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
